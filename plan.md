# Plan: 新闻来源多样性优化

## 状态：已归档（记忆固化完成于 2026-02-19）

---

## 需求描述

当前早报推送的 Top 10 文章全部来自同一个新闻源（能源界），没有达到多来源覆盖的预期效果。需要确保推送内容来自多个不同的新闻源。

---

## 根本原因（已验证）

经过数据验证，问题不在排名算法，而在 **SeenArticle 把所有历史文章锁死**：

| 来源 | 列表页链接数 | SeenArticle 已记录数 | 每次可爬新文章数 |
|------|------------|---------------------|----------------|
| 国家能源局 | 44 | 44 | **0 篇** |
| 新华社 | 15 | 15 | **0 篇** |
| 能源界 | 12 | 19 | **12 篇**（文章更新快，旧 URL 已不在列表页）|

结论：国家能源局和新华社的列表页文章已被全部标记为已见，每次爬取没有新文章进入排名，所以 Top 10 全部来自能源界。

---

## 技术难点分析

### 难点 1：SeenArticle 的设计目的与副作用
- SeenArticle 的目的是避免重复推送同一篇文章
- 但当一个来源的列表页文章全部被标记后，该来源永远无法贡献新文章
- 国家能源局更新慢（列表页只有 44 篇，全部已见），新华社同理

### 难点 2：如何定义"新文章"
- 当前定义：URL 不在 SeenArticle 表中
- 问题：国家能源局的文章发布后很长时间才被爬到，第一次爬到就标记为已见，之后永远不会再推送
- 需要重新思考：是否应该基于"发布时间"而非"是否已见"来判断是否推送

### 难点 3：时效性与去重的平衡
- 如果改为基于发布时间过滤，需要确定时间窗口（如：只推送 24 小时内的文章）
- 同时仍需避免同一篇文章被重复推送

---

## 可能的实现路径

### 方案 A：基于发布时间过滤（推荐）
将"新文章"的判断从"URL 未见过"改为"发布时间在 N 小时内且未推送过"：

1. 爬取时不再过滤 SeenArticle，而是抓取列表页所有文章
2. 过滤条件改为：`published_at >= 昨天 00:00`（早报推送前一天的文章）
3. SeenArticle 改为记录"已推送"的文章，而非"已爬取"的文章
4. 每次推送后，将本次推送的文章 URL 写入 SeenArticle，避免下次重复推送

**改动范围：**
- `backend/services/news_crawler.py`：修改 `_crawl_one_source()`，改变过滤逻辑
- `backend/tasks/scheduler.py`：推送后写入 SeenArticle 的时机不变，但语义变为"已推送"

**优点：** 根治问题，每天都能从所有来源获取当天新文章
**缺点：** 需要文章有准确的发布时间（当前已有 `published_at` 字段）

### 方案 B：SeenArticle 定期清理
定期（如每天凌晨）清理 SeenArticle 中超过 7 天的记录：

**改动范围：**
- `backend/tasks/scheduler.py`：添加定时清理任务

**优点：** 改动最小
**缺点：** 治标不治本，7 天内的文章仍无法重新进入排名

### 方案 C：SeenArticle 改为记录"已推送"
只有实际推送过的文章才写入 SeenArticle，爬取时仍过滤已推送文章：

**改动范围：**
- `backend/tasks/scheduler.py`：将 SeenArticle 写入时机从"爬取后"改为"推送后"
- `backend/services/news_crawler.py`：移除爬取时写入 SeenArticle 的逻辑

**优点：** 语义更准确，未推送的文章下次仍可参与排名
**缺点：** 需要清理历史数据（当前 SeenArticle 中有大量"已爬取但未推送"的记录）

---

## 需要验证的核心假设

1. **假设 1**：国家能源局和新华社的文章有准确的 `published_at` 时间（需验证爬取逻辑）
2. **假设 2**：方案 A 实施后，每天能从国家能源局和新华社各获取至少 1-3 篇当天文章
3. **假设 3**：方案 C 中，将 SeenArticle 写入时机改为"推送后"不会引入重复推送风险

---

## 推荐方案

**方案 C（SeenArticle 改为记录"已推送"）**，同时清理历史数据。

理由：
- 语义最准确：SeenArticle 应该记录"已推送"，而非"已爬取"
- 改动范围小：只需修改 `scheduler.py` 中写入 SeenArticle 的时机
- 不依赖发布时间的准确性（方案 A 的风险点）
- 清理历史数据后，国家能源局和新华社的文章可以重新参与排名

**实施步骤：**
1. 清理 SeenArticle 历史数据（保留最近 7 天已推送的文章）
2. 修改 `news_crawler.py`：移除爬取时写入 SeenArticle 的逻辑
3. 修改 `scheduler.py`：在推送成功后写入 SeenArticle

---

## 验收要求（概念层）

请确认以下内容后，输入"确认"进入骨架层：
1. 是否认可"SeenArticle 改为记录已推送"的方案？
2. 是否同意清理历史 SeenArticle 数据？
3. 是否有其他需要考虑的边界情况？
